import os
import datetime
import pandas as pd
import numpy as np
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from scipy.sparse import hstack
import argparse
import matplotlib.pyplot as plt
import seaborn as sns
import re

class PhishingUrlDetection:
    
    def __init__(self, dataset_dir, result_dir="./results", sequence_length=200, categories=['phishing', 'legitimate']):
        self.params = {
            'dataset_dir': dataset_dir,
            'result_dir': result_dir,
            'sequence_length': sequence_length,
            'categories': categories
        }

    def load_and_vectorize_data(self):
        print("ğŸ”„ Loading CSV data...")

        # æ„é€ è·¯å¾„
        train_path = os.path.join(self.params['dataset_dir'], "train.csv")
        val_path = os.path.join(self.params['dataset_dir'], "val.csv")
        test_path = os.path.join(self.params['dataset_dir'], "test.csv")

        # ç”¨ pandas åŠ è½½
        train_df = pd.read_csv(train_path)
        val_df = pd.read_csv(val_path)
        test_df = pd.read_csv(test_path)

        # ç®€æ´å˜é‡å
        raw_x_train = train_df['url'].tolist()
        raw_y_train = train_df['label'].tolist()

        raw_x_val = val_df['url'].tolist()
        raw_y_val = val_df['label'].tolist()

        raw_x_test = test_df['url'].tolist()
        raw_y_test = test_df['label'].tolist()

        # tokenizer
        tokenizer = TfidfVectorizer(lowercase=True, max_features=1000)
        tokenizer.fit(raw_x_train + raw_x_val + raw_x_test)
        
        # æå– TF-IDF ç‰¹å¾
        X_train_tfidf = tokenizer.transform(raw_x_train)
        X_val_tfidf = tokenizer.transform(raw_x_val)
        X_test_tfidf = tokenizer.transform(raw_x_test)

        # è‡ªå®šä¹‰ç»Ÿè®¡ç‰¹å¾
        def extract_url_features(url):
            length = len(url)  # URL é•¿åº¦
            num_slashes = url.count("/")  # URL ä¸­çš„æ–œæ æ•°
            num_query_params = url.count("=")  # URL æŸ¥è¯¢å‚æ•°æ•°
            has_https = 1 if url.startswith("https") else 0  # æ˜¯å¦æ˜¯ https

            # æå–åŸŸåå’Œå­åŸŸå
            domain_match = re.search(r"https?://([A-Za-z_0-9.-]+).*", url)
            domain = domain_match.group(1) if domain_match else ''
            subdomain_count = domain.count('.') - 1  # è®¡ç®—å­åŸŸåæ•°

            return [length, num_slashes, num_query_params, has_https, subdomain_count]

        # æå–æ‰€æœ‰URLçš„ç»Ÿè®¡ç‰¹å¾
        X_train_custom = np.array([extract_url_features(url) for url in raw_x_train])
        X_val_custom = np.array([extract_url_features(url) for url in raw_x_val])
        X_test_custom = np.array([extract_url_features(url) for url in raw_x_test])

        # åˆå¹¶ TF-IDF å’Œè‡ªå®šä¹‰ç‰¹å¾
        X_train = hstack([X_train_tfidf, X_train_custom])
        X_val = hstack([X_val_tfidf, X_val_custom])
        X_test = hstack([X_test_tfidf, X_test_custom])

        # Label ç¼–ç ä¸º one-hot
        encoder = LabelEncoder()
        encoder.fit(self.params['categories'])

        y_train = encoder.transform(raw_y_train)
        y_val = encoder.transform(raw_y_val)
        y_test = encoder.transform(raw_y_test)

        print("âœ… Data loaded successfully.")
        
        return (X_train, y_train), (X_val, y_val), (X_test, y_test)

    def train_and_evaluate(self, X_train, y_train, X_val, y_val, X_test, y_test, model_name='SVM', epochs=20):
        # æ ¹æ®æ¨¡å‹é€‰æ‹©ä¸åŒçš„æœºå™¨å­¦ä¹ æ¨¡å‹
        if model_name == 'SVM':
            model = SVC(kernel='linear')
        elif model_name == 'RandomForest':
            model = RandomForestClassifier(n_estimators=100, random_state=42)
        elif model_name == 'LogisticRegression':
            model = LogisticRegression(max_iter=1000)
        elif model_name == 'KNeighbors':
            model = KNeighborsClassifier(n_neighbors=5)
        else:
            raise ValueError(f"Unknown model: {model_name}")
        
        # ä¿å­˜æ¯ä¸ªepochçš„å‡†ç¡®ç‡
        train_accs = []
        val_accs = []

        # æ¨¡æ‹Ÿæ¯ä¸ªepoch
        for epoch in range(epochs):
            print(f"Epoch {epoch + 1}/{epochs}...")

            # è®­ç»ƒæ¨¡å‹
            model.fit(X_train, y_train)

            # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹
            y_pred_val = model.predict(X_val)
            val_acc = accuracy_score(y_val, y_pred_val)
            val_accs.append(val_acc)
            print(f"Validation Accuracy: {val_acc:.4f}")

            # è®­ç»ƒé›†ä¸Šçš„å‡†ç¡®ç‡
            y_pred_train = model.predict(X_train)
            train_acc = accuracy_score(y_train, y_pred_train)
            train_accs.append(train_acc)
            print(f"Training Accuracy: {train_acc:.4f}")

        # ç»˜åˆ¶è®­ç»ƒå’ŒéªŒè¯å‡†ç¡®ç‡
        plt.figure(figsize=(8, 6))
        plt.plot(range(1, epochs + 1), train_accs, label='train_acc')
        plt.plot(range(1, epochs + 1), val_accs, label='val_acc')
        plt.xlabel('Epochs')
        plt.ylabel('Accuracy')
        plt.legend()
        plt.title('Training and Validation Accuracy')
        result_dir = self.create_result_dir(model_name)
        plt.savefig(os.path.join(result_dir, 'accuracy_plot.png'))
        plt.close()

        # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹
        y_pred_test = model.predict(X_test)
        test_acc = accuracy_score(y_test, y_pred_test)
        print(f"Test Accuracy: {test_acc:.4f}")

        # è¾“å‡ºåˆ†ç±»æŠ¥å‘Š
        print("Classification Report (Test Set):")
        print(classification_report(y_test, y_pred_test))

        # æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(y_test, y_pred_test)
        print("Confusion Matrix:")
        print(cm)

        # ç»˜åˆ¶å¹¶ä¿å­˜æ··æ·†çŸ©é˜µ
        self.save_confusion_matrix(cm, model_name)

    def save_confusion_matrix(self, cm, model_name):
        # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=self.params['categories'], yticklabels=self.params['categories'])
        plt.xlabel('Predicted')
        plt.ylabel('True')
        plt.title('Confusion Matrix')
        
        # ä¿å­˜å›¾åƒ
        result_dir = self.create_result_dir(model_name)
        plt.savefig(os.path.join(result_dir, 'confusion_matrix.png'))
        plt.close()

    def create_result_dir(self, model_name):
        # ç”Ÿæˆæ¨¡å‹åç§°æ–‡ä»¶å¤¹
        model_dir = os.path.join(self.params['result_dir'], model_name)
        if not os.path.exists(model_dir):
            os.makedirs(model_dir)

        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        result_dir = os.path.join(model_dir, timestamp)

        if not os.path.exists(result_dir):
            os.makedirs(result_dir)
        return result_dir


# ä¸»ç¨‹åº
def main():
    parser = argparse.ArgumentParser(description="Train Phishing URL Detection model.")
    parser.add_argument("-dataset", "--dataset_dir", type=str, default="/mnt/nvme0n1/Tsinghua_Node11/hh/safety/dephides/dataset/balanced_dataset", help="Path to the dataset directory")
    parser.add_argument("-result", "--result_dir", type=str, default="./ml_results", help="Path to save the results")
    parser.add_argument("-model", "--model_name", type=str, default="SVM", choices=['SVM', 'RandomForest', 'LogisticRegression', 'KNeighbors'], help="Machine learning model name")
    parser.add_argument("-e", "--epochs", type=int, default=20, help="Number of epochs for training")
    args = parser.parse_args()

    phishing_url_detection = PhishingUrlDetection(dataset_dir=args.dataset_dir, result_dir=args.result_dir)
    
    # åŠ è½½å¹¶å‘é‡åŒ–æ•°æ®
    (X_train, y_train), (X_val, y_val), (X_test, y_test) = phishing_url_detection.load_and_vectorize_data()
    
    # è®­ç»ƒå¹¶è¯„ä¼°æ¨¡å‹
    phishing_url_detection.train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, model_name=args.model_name, epochs=args.epochs)

if __name__ == '__main__':
    main()
